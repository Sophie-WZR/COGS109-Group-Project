{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d9c4d5-da57-4263-a758-6f36c33c91e0",
   "metadata": {},
   "source": [
    "Model 1: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3fbee3-eadb-4534-b5ab-b14685c76b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# IMPORTS\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03ee82-0ea1-4d50-b0bf-2d8e7b15d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FEATURE EXTRACTION\n",
    "# ============================================\n",
    "\n",
    "def extract_features(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    features = []\n",
    "    \n",
    "    # Color histograms (8 bins per channel)\n",
    "    for i in range(3):\n",
    "        hist = cv2.calcHist([img_rgb], [i], None, [8], [0, 256])\n",
    "        hist = hist.flatten() / hist.sum()\n",
    "        features.extend(hist)\n",
    "    \n",
    "    # Edge density\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    edge_density = np.sum(edges > 0) / edges.size\n",
    "    features.append(edge_density)\n",
    "    \n",
    "    # Color statistics\n",
    "    for i in range(3):\n",
    "        features.append(np.mean(img_rgb[:,:,i]))\n",
    "        features.append(np.std(img_rgb[:,:,i]))\n",
    "    \n",
    "    # Brightness and contrast\n",
    "    features.append(np.mean(gray))\n",
    "    features.append(np.std(gray))\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be311c8-fbe7-428a-a7d4-1dbad7fdef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# LOAD DATASET\n",
    "# ============================================\n",
    "\n",
    "def load_dataset(base_path):\n",
    "    label_map = {'01-minor': 0, '02-moderate': 1, '03-severe': 2}\n",
    "    \n",
    "    def load_split(split_name):\n",
    "        X, y = [], []\n",
    "        split_path = os.path.join(base_path, split_name)\n",
    "        print(f\"Loading {split_name} data...\")\n",
    "        \n",
    "        for label_folder in sorted(os.listdir(split_path)):\n",
    "            if label_folder.startswith('.'):\n",
    "                continue\n",
    "            label = label_map[label_folder]\n",
    "            folder_path = os.path.join(split_path, label_folder)\n",
    "            \n",
    "            count = 0\n",
    "            for img_file in os.listdir(folder_path):\n",
    "                if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    img_path = os.path.join(folder_path, img_file)\n",
    "                    features = extract_features(img_path)\n",
    "                    if features is not None:\n",
    "                        X.append(features)\n",
    "                        y.append(label)\n",
    "                        count += 1\n",
    "            \n",
    "            print(f\"  {label_folder}: {count} images\")\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    X_train, y_train = load_split('training')\n",
    "    print()\n",
    "    X_test, y_test = load_split('validation')\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "dataset_path = \"/Users/stephanieluo/Downloads/data3a\"\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_dataset(dataset_path)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DATASET LOADED\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Training: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test: {X_test.shape[0]} samples\")\n",
    "print(f\"Classes: Minor({np.sum(y_train==0)}), Moderate({np.sum(y_train==1)}), Severe({np.sum(y_train==2)})\")\n",
    "\n",
    "# Features\n",
    "feature_names = []\n",
    "for color in ['R', 'G', 'B']:\n",
    "    for i in range(8):\n",
    "        feature_names.append(f'{color}_hist_bin{i}')\n",
    "feature_names.extend(['edge_density', 'mean_R', 'std_R', 'mean_G', 'std_G', \n",
    "                      'mean_B', 'std_B', 'brightness', 'contrast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d8ce2-3a4c-4bf1-9d95-ecabcb223250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# VARIANT 1: GINI\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"VARIANT 1: Gini\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "dt_shallow = DecisionTreeClassifier(\n",
    "    max_depth=4,\n",
    "    criterion='gini',\n",
    "    random_state=42,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=14\n",
    ")\n",
    "\n",
    "dt_shallow.fit(X_train, y_train)\n",
    "y_train_pred_v1 = dt_shallow.predict(X_train)\n",
    "y_test_pred_v1 = dt_shallow.predict(X_test)\n",
    "\n",
    "train_acc_v1 = accuracy_score(y_train, y_train_pred_v1)\n",
    "test_acc_v1 = accuracy_score(y_test, y_test_pred_v1)\n",
    "\n",
    "print(f\"Train Acc: {train_acc_v1:.4f} | Test Acc: {test_acc_v1:.4f}\")\n",
    "print(f\"Depth: {dt_shallow.get_depth()} | Leaves: {dt_shallow.get_n_leaves()}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_v1, \n",
    "                          target_names=['Minor', 'Moderate', 'Severe'], digits=3))\n",
    "\n",
    "cm_v1 = confusion_matrix(y_test, y_test_pred_v1)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_v1, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Minor', 'Moderate', 'Severe'],\n",
    "            yticklabels=['Minor', 'Moderate', 'Severe'])\n",
    "plt.title('Confusion Matrix - Variant 1 (Gini)')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('cm_v1.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "feature_imp_v1 = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': dt_shallow.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "print(feature_imp_v1.head(10).to_string(index=False))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_10 = feature_imp_v1.head(10)\n",
    "plt.barh(range(len(top_10)), top_10['importance'], color='steelblue')\n",
    "plt.yticks(range(len(top_10)), top_10['feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance - Variant 1')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('feat_imp_v1.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de12e9-bb8b-4a83-ab97-bc4d789f311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# VARIANT 2: PRUNED TREE\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"VARIANT 2: Pruned Tree\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Grow deep tree\n",
    "dt_deep = DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    random_state=42,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10\n",
    ")\n",
    "dt_deep.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Initial tree: Depth={dt_deep.get_depth()}, Leaves={dt_deep.get_n_leaves()}\")\n",
    "\n",
    "# Pruning path\n",
    "path = dt_deep.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Find optimal alpha via CV\n",
    "pruned_trees = []\n",
    "cv_scores = []\n",
    "valid_alphas = []\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for alpha in ccp_alphas:\n",
    "    dt_temp = DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        random_state=42,\n",
    "        ccp_alpha=alpha\n",
    "    )\n",
    "    dt_temp.fit(X_train, y_train)\n",
    "    \n",
    "    if dt_temp.get_n_leaves() >= 5 and dt_temp.get_n_leaves() < dt_deep.get_n_leaves():\n",
    "        pruned_trees.append(dt_temp)\n",
    "        valid_alphas.append(alpha)\n",
    "        cv_score = cross_val_score(dt_temp, X_train, y_train, cv=kfold).mean()\n",
    "        cv_scores.append(cv_score)\n",
    "\n",
    "optimal_idx = np.argmax(cv_scores)\n",
    "dt_pruned = pruned_trees[optimal_idx]\n",
    "\n",
    "y_train_pred_v2 = dt_pruned.predict(X_train)\n",
    "y_test_pred_v2 = dt_pruned.predict(X_test)\n",
    "\n",
    "train_acc_v2 = accuracy_score(y_train, y_train_pred_v2)\n",
    "test_acc_v2 = accuracy_score(y_test, y_test_pred_v2)\n",
    "\n",
    "print(f\"\\nPruned tree: Depth={dt_pruned.get_depth()}, Leaves={dt_pruned.get_n_leaves()}\")\n",
    "print(f\"Train Acc: {train_acc_v2:.4f} | Test Acc: {test_acc_v2:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_v2, \n",
    "                          target_names=['Minor', 'Moderate', 'Severe'], digits=3))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_v2 = confusion_matrix(y_test, y_test_pred_v2)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_v2, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=['Minor', 'Moderate', 'Severe'],\n",
    "            yticklabels=['Minor', 'Moderate', 'Severe'])\n",
    "plt.title('Confusion Matrix - Variant 2 (Pruned)')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('cm_v2.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Feature\n",
    "feature_imp_v2 = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': dt_pruned.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "print(feature_imp_v2.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739450b8-d46e-4c40-8f6a-32b1c1ab65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# VARIANT 3: ENTROPY\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"VARIANT 3: Entropy\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "dt_entropy = DecisionTreeClassifier(\n",
    "    max_depth=4,\n",
    "    criterion='entropy',\n",
    "    random_state=42,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=14\n",
    ")\n",
    "\n",
    "dt_entropy.fit(X_train, y_train)\n",
    "y_train_pred_v3 = dt_entropy.predict(X_train)\n",
    "y_test_pred_v3 = dt_entropy.predict(X_test)\n",
    "\n",
    "train_acc_v3 = accuracy_score(y_train, y_train_pred_v3)\n",
    "test_acc_v3 = accuracy_score(y_test, y_test_pred_v3)\n",
    "\n",
    "print(f\"Train Acc: {train_acc_v3:.4f} | Test Acc: {test_acc_v3:.4f}\")\n",
    "print(f\"Depth: {dt_entropy.get_depth()} | Leaves: {dt_entropy.get_n_leaves()}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_v3, \n",
    "                          target_names=['Minor', 'Moderate', 'Severe'], digits=3))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_v3 = confusion_matrix(y_test, y_test_pred_v3)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_v3, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Minor', 'Moderate', 'Severe'],\n",
    "            yticklabels=['Minor', 'Moderate', 'Severe'])\n",
    "plt.title('Confusion Matrix - Variant 3 (Entropy)')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('cm_v3.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "feature_imp_v3 = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': dt_entropy.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "print(feature_imp_v3.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82796f0-6d25-4508-a9a4-f6b913d8f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# COMPARISON: ALL THREE VARIANTS\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"COMPARISON: ALL THREE VARIANTS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Comparison Table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Variant': ['Variant 1', 'Variant 2', 'Variant 3'],\n",
    "    'Description': ['Gini (depth=4)', 'Pruned Tree', 'Entropy (depth=4)'],\n",
    "    'Criterion': ['Gini', 'Gini (Pruned)', 'Entropy'],\n",
    "    'Train_Acc': [train_acc_v1, train_acc_v2, train_acc_v3],\n",
    "    'Test_Acc': [test_acc_v1, test_acc_v2, test_acc_v3],\n",
    "    'Gen_Gap': [\n",
    "        abs(train_acc_v1 - test_acc_v1),\n",
    "        abs(train_acc_v2 - test_acc_v2),\n",
    "        abs(train_acc_v3 - test_acc_v3)\n",
    "    ],\n",
    "    'Depth': [dt_shallow.get_depth(), dt_pruned.get_depth(), dt_entropy.get_depth()],\n",
    "    'Leaves': [dt_shallow.get_n_leaves(), dt_pruned.get_n_leaves(), dt_entropy.get_n_leaves()]\n",
    "})\n",
    "\n",
    "print(\"MODEL COMPARISON TABLE:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "comparison_df.to_csv('model_comparison.csv', index=False)\n",
    "\n",
    "# Winner\n",
    "best_idx = comparison_df['Test_Acc'].idxmax()\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ğŸ† WINNER: {comparison_df.loc[best_idx, 'Variant']} - {comparison_df.loc[best_idx, 'Description']}\")\n",
    "print(f\"   Test Accuracy: {comparison_df.loc[best_idx, 'Test_Acc']:.4f}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Figure 1: Train vs Test Accuracy\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "variants = ['V1\\nGini', 'V2\\nPruned', 'V3\\nEntropy']\n",
    "train_accs = [train_acc_v1, train_acc_v2, train_acc_v3]\n",
    "test_accs = [test_acc_v1, test_acc_v2, test_acc_v3]\n",
    "\n",
    "x = np.arange(len(variants))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, train_accs, width, label='Train', color='#4CAF50', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, test_accs, width, label='Test', color='#2196F3', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Train vs Test Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(variants)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.axvspan(best_idx - 0.4, best_idx + 0.4, alpha=0.15, color='gold')\n",
    "ax.text(best_idx, 0.95, 'â˜… WINNER', ha='center', fontsize=11, \n",
    "        fontweight='bold', color='darkgoldenrod')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Figure 2: Confusion Matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "cms = [cm_v1, cm_v2, cm_v3]\n",
    "titles = ['V1: Gini', 'V2: Pruned', 'V3: Entropy']\n",
    "cmaps = ['Blues', 'Oranges', 'Greens']\n",
    "\n",
    "for idx, (ax, cm, title, cmap) in enumerate(zip(axes, cms, titles, cmaps)):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, ax=ax,\n",
    "                xticklabels=['Minor', 'Mod', 'Severe'],\n",
    "                yticklabels=['Minor', 'Mod', 'Severe'])\n",
    "    ax.set_title(f'{title}\\nAcc: {[test_acc_v1, test_acc_v2, test_acc_v3][idx]:.3f}', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Actual' if idx == 0 else '')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    \n",
    "    if idx == best_idx:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('gold')\n",
    "            spine.set_linewidth(4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_cms.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Figure 3: Generalization Gap\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Test Error\n",
    "test_errors = [1-test_acc_v1, 1-test_acc_v2, 1-test_acc_v3]\n",
    "bars = ax1.bar(variants, test_errors, color=['#3498db', '#e74c3c', '#2ecc71'], alpha=0.8)\n",
    "ax1.set_ylabel('Test Error', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Test Error Comparison', fontsize=13, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, err in zip(bars, test_errors):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.005,\n",
    "             f'{err:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Generalization Gap\n",
    "gen_gaps = comparison_df['Gen_Gap'].values\n",
    "bars = ax2.bar(variants, gen_gaps, color=['#FF9800', '#FF5722', '#9C27B0'], alpha=0.8)\n",
    "ax2.set_ylabel('|Train - Test| Accuracy', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Generalization Gap', fontsize=13, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, gap in zip(bars, gen_gaps):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.002,\n",
    "             f'{gap:.4f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_errors.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Figure 4: Per-Class F1 Scores Heatmap\n",
    "metrics_v1 = precision_recall_fscore_support(y_test, y_test_pred_v1, average=None)\n",
    "metrics_v2 = precision_recall_fscore_support(y_test, y_test_pred_v2, average=None)\n",
    "metrics_v3 = precision_recall_fscore_support(y_test, y_test_pred_v3, average=None)\n",
    "\n",
    "f1_matrix = np.array([\n",
    "    metrics_v1[2],\n",
    "    metrics_v2[2],\n",
    "    metrics_v3[2]\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "im = ax.imshow(f1_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "ax.set_xticks(np.arange(3))\n",
    "ax.set_yticks(np.arange(3))\n",
    "ax.set_xticklabels(['Minor', 'Moderate', 'Severe'])\n",
    "ax.set_yticklabels(['Variant 1', 'Variant 2', 'Variant 3'])\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax.text(j, i, f'{f1_matrix[i, j]:.3f}',\n",
    "               ha='center', va='center', color='black', fontweight='bold')\n",
    "\n",
    "plt.colorbar(im, ax=ax, label='F1-Score')\n",
    "ax.set_title('F1-Score by Class and Variant', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Damage Class', fontsize=12)\n",
    "ax.set_ylabel('Model Variant', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_f1_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Figure 5: Model Complexity vs Performance\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "leaves = comparison_df['Leaves'].values\n",
    "test_accs_all = comparison_df['Test_Acc'].values\n",
    "\n",
    "scatter = ax.scatter(leaves, test_accs_all, s=400, \n",
    "                    c=['#3498db', '#e74c3c', '#2ecc71'], \n",
    "                    alpha=0.6, edgecolors='black', linewidth=2)\n",
    "\n",
    "for i, txt in enumerate(['V1', 'V2', 'V3']):\n",
    "    ax.annotate(txt, (leaves[i], test_accs_all[i]),\n",
    "               ha='center', va='center', fontsize=13, \n",
    "               fontweight='bold', color='white')\n",
    "\n",
    "ax.set_xlabel('Number of Leaves (Model Complexity)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Test Accuracy', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Model Complexity vs Performance Trade-off', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_complexity.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Baseline Comparison\n",
    "majority_class = Counter(y_train).most_common(1)[0][0]\n",
    "baseline_acc = accuracy_score(y_test, [majority_class] * len(y_test))\n",
    "\n",
    "print(f\"\\nBaseline (majority class): {baseline_acc:.4f}\")\n",
    "print(f\"Best model improvement: {(comparison_df.loc[best_idx, 'Test_Acc'] - baseline_acc)*100:.2f}pp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
