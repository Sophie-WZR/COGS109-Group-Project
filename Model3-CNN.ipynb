{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b57eaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch==2.9.0 (from torchvision)\n",
      "  Downloading torch-2.9.0-cp310-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: filelock in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from torch==2.9.0->torchvision) (2025.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from jinja2->torch==2.9.0->torchvision) (2.1.1)\n",
      "Downloading torchvision-0.24.0-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.9.0-cp310-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.8.0\n",
      "    Uninstalling torch-2.8.0:\n",
      "      Successfully uninstalled torch-2.8.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.2.1 requires torch==2.2.1, but you have torch 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.9.0 torchvision-0.24.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4987e8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "\n",
      "CondaValueError: You have chosen a non-default solver backend (libmamba) but it was not recognized. Choose one of: classic\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision torchaudio cpuonly -c pytorch -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "075788e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imagehash in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (4.3.2)\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.21-py3-none-any.whl.metadata (62 kB)\n",
      "Requirement already satisfied: PyWavelets in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from imagehash) (1.4.1)\n",
      "Requirement already satisfied: numpy in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from imagehash) (1.26.4)\n",
      "Requirement already satisfied: pillow in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from imagehash) (11.3.0)\n",
      "Requirement already satisfied: scipy in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from imagehash) (1.15.2)\n",
      "Requirement already satisfied: torch in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from timm) (2.9.0)\n",
      "Requirement already satisfied: torchvision in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from timm) (0.24.0)\n",
      "Requirement already satisfied: pyyaml in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from timm) (6.0)\n",
      "Requirement already satisfied: huggingface_hub in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from timm) (0.34.4)\n",
      "Requirement already satisfied: safetensors in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from timm) (0.6.2)\n",
      "Requirement already satisfied: filelock in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from huggingface_hub->timm) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from huggingface_hub->timm) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: requests in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from huggingface_hub->timm) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from huggingface_hub->timm) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from huggingface_hub->timm) (1.1.7)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from torch->timm) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from torch->timm) (3.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy>=1.13.3->torch->timm) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wangzhuoran/anaconda3/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2025.7.14)\n",
      "Downloading timm-1.0.21-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: timm\n",
      "Successfully installed timm-1.0.21\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imagehash timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9cd73b",
   "metadata": {},
   "source": [
    "### 1. Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "\n",
      "Class counts by split:\n",
      " label  minor  moderate  severe\n",
      "split                         \n",
      "test      82        75      91\n",
      "train    452       463     468\n",
      "Test majority baseline: severe = 0.367\n"
     ]
    }
   ],
   "source": [
    "# ====== Minimal Car Damage Pipeline: EDA -> Train -> Report ======\n",
    "from pathlib import Path\n",
    "import os, random, json\n",
    "import numpy as np, pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "TRAIN_DIR = Path(\"training\")  \n",
    "TEST_DIR  = Path(\"validation\")\n",
    "\n",
    "assert TRAIN_DIR.is_dir(), f\"TRAIN_DIR not found: {TRAIN_DIR}\"\n",
    "assert TEST_DIR.is_dir(),  f\"TEST_DIR not found: {TEST_DIR}\"\n",
    "\n",
    "SEED=42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMSIZE = 224\n",
    "IMNET_MEAN = np.array([0.485,0.456,0.406], dtype=\"float32\")\n",
    "IMNET_STD  = np.array([0.229,0.224,0.225], dtype=\"float32\")\n",
    "IMG_EXT = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\"}\n",
    "CLASSES = [\"minor\",\"moderate\",\"severe\"]\n",
    "LBL = {c:i for i,c in enumerate(CLASSES)}\n",
    "\n",
    "ART = Path(\"artifacts\"); ART.mkdir(exist_ok=True)\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# ---- 1) Scan folders ----\n",
    "def label_from_name(name:str):\n",
    "    n=name.lower()\n",
    "    if \"minor\" in n: return \"minor\"\n",
    "    if \"moderate\" in n: return \"moderate\"\n",
    "    if \"severe\" in n: return \"severe\"\n",
    "    return None\n",
    "\n",
    "def scan_split(split_dir: Path, split_name: str):\n",
    "    rows=[]\n",
    "    for pdir in sorted([d for d in split_dir.iterdir() if d.is_dir()]):\n",
    "        lab = label_from_name(pdir.name)\n",
    "        if lab is None: \n",
    "            continue\n",
    "        for img in pdir.glob(\"*\"):\n",
    "            if img.suffix.lower() in IMG_EXT:\n",
    "                rows.append({\"path\": str(img.resolve()), \"label\": lab, \"split\": split_name})\n",
    "    return rows\n",
    "\n",
    "df = pd.DataFrame(scan_split(TRAIN_DIR,\"train\") + scan_split(TEST_DIR,\"test\"))\n",
    "assert len(df)>0, \"No images found—check paths.\"\n",
    "df = df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "# ---- 2) (Simple) EDA ----\n",
    "counts = df.groupby([\"split\",\"label\"]).size().unstack(fill_value=0)\n",
    "print(\"\\nClass counts by split:\\n\", counts)\n",
    "counts.to_csv(ART/\"class_counts_by_split.csv\")\n",
    "\n",
    "test_counts = counts.loc[\"test\"]\n",
    "baseline_label = test_counts.idxmax()\n",
    "baseline_acc = test_counts.max() / test_counts.sum()\n",
    "print(f\"Test majority baseline: {baseline_label} = {baseline_acc:.3f}\")\n",
    "\n",
    "# ---- 3) Tiny image check: drop unreadable files upfront ----\n",
    "def is_good_image(p):\n",
    "    try:\n",
    "        with Image.open(p) as im:\n",
    "            im.verify()\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "mask = df[\"path\"].map(is_good_image)\n",
    "bad = df.loc[~mask, \"path\"].tolist()\n",
    "if bad:\n",
    "    print(f\"Dropping {len(bad)} unreadable images\")\n",
    "df = df[mask].reset_index(drop=True)\n",
    "\n",
    "# ---- 4) Datasets (no torchvision, no multiprocessing pitfalls) ----\n",
    "def to_tensor(img: Image.Image):\n",
    "    img = img.convert(\"RGB\").resize((IMSIZE,IMSIZE))\n",
    "    arr = np.asarray(img).astype(\"float32\")/255.0\n",
    "    arr = (arr - IMNET_MEAN) / IMNET_STD\n",
    "    arr = arr.transpose(2,0,1)  # CHW\n",
    "    return torch.from_numpy(arr)\n",
    "\n",
    "class FrameDS(Dataset):\n",
    "    def __init__(self, frame: pd.DataFrame, train: bool=False):\n",
    "        self.df = frame.reset_index(drop=True).copy()\n",
    "        self.train = train\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row[\"path\"])\n",
    "        x = to_tensor(img)\n",
    "        y = LBL[row[\"label\"]]\n",
    "        return x, y\n",
    "\n",
    "train_df = df[df.split==\"train\"].copy()\n",
    "test_df  = df[df.split==\"test\"].copy()\n",
    "\n",
    "train_loader = DataLoader(FrameDS(train_df, True), batch_size=32, shuffle=True,  num_workers=0, pin_memory=False)\n",
    "test_loader  = DataLoader(FrameDS(test_df,  False), batch_size=64, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1416c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_nll_and_counts(model, loader):\n",
    "    \"\"\"\n",
    "    Compute total negative log-likelihood and number of samples.\n",
    "    Uses CrossEntropyLoss with reduction='sum', which matches NLL.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_nll = 0.0\n",
    "    total_n = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits = model(x)\n",
    "        # sum of per-sample NLL\n",
    "        nll = nn.CrossEntropyLoss(reduction=\"sum\")(logits, y)\n",
    "        total_nll += nll.item()\n",
    "        total_n += x.size(0)\n",
    "\n",
    "    return total_nll, total_n\n",
    "\n",
    "\n",
    "def compute_aic_bic(model, loader, variant_name: str, out_json_path: Path):\n",
    "    \"\"\"\n",
    "    Compute AIC and BIC for a classification model on a given loader.\n",
    "    Saves results to JSON under artifacts.\n",
    "    \"\"\"\n",
    "    nll, n = compute_nll_and_counts(model, loader)\n",
    "\n",
    "    # number of trainable parameters\n",
    "    k = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    aic = 2 * k + 2 * nll\n",
    "    bic = k * math.log(n) + 2 * nll\n",
    "\n",
    "    print(f\"\\n===== {variant_name}: AIC / BIC =====\")\n",
    "    print(f\"Samples (n): {n}\")\n",
    "    print(f\"Parameters (k): {k}\")\n",
    "    print(f\"Negative log-likelihood (NLL): {nll:.2f}\")\n",
    "    print(f\"AIC: {aic:.2f}\")\n",
    "    print(f\"BIC: {bic:.2f}\")\n",
    "\n",
    "    with open(out_json_path, \"w\") as f:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"variant\": variant_name,\n",
    "                \"n\": int(n),\n",
    "                \"k\": int(k),\n",
    "                \"nll\": float(nll),\n",
    "                \"aic\": float(aic),\n",
    "                \"bic\": float(bic),\n",
    "            },\n",
    "            f,\n",
    "            indent=2,\n",
    "        )\n",
    "\n",
    "    return aic, bic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd316e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Train/Test run for Checkpoint-1 model variant =====\n",
      "Epoch 01 | train_loss=1.0672 | test_acc=0.524 | macroF1=0.512\n",
      "Epoch 02 | train_loss=0.9649 | test_acc=0.637 | macroF1=0.612\n",
      "Epoch 03 | train_loss=0.8477 | test_acc=0.661 | macroF1=0.644\n",
      "Epoch 04 | train_loss=0.7517 | test_acc=0.685 | macroF1=0.676\n",
      "Epoch 05 | train_loss=0.6521 | test_acc=0.665 | macroF1=0.663\n",
      "Epoch 06 | train_loss=0.5755 | test_acc=0.677 | macroF1=0.676\n",
      "Epoch 07 | train_loss=0.4950 | test_acc=0.677 | macroF1=0.680\n",
      "Epoch 08 | train_loss=0.4260 | test_acc=0.702 | macroF1=0.702\n",
      "\n",
      "FINAL — Test Acc: 0.702 | Macro-F1: 0.702\n",
      "Saved single-run artifacts in: /Users/wangzhuoran/Desktop/COGS 109 project/artifacts\n",
      "\n",
      "===== 3-fold Cross-Validation for Checkpoint-1 CNN Variant =====\n",
      "\n",
      "--- Fold 1/3 ---\n",
      "  Epoch 01 | train_loss=1.0850 | val_acc=0.495 | val_F1=0.494\n",
      "  Epoch 02 | train_loss=1.0119 | val_acc=0.564 | val_F1=0.543\n",
      "  Epoch 03 | train_loss=0.9375 | val_acc=0.627 | val_F1=0.610\n",
      "  Epoch 04 | train_loss=0.8507 | val_acc=0.649 | val_F1=0.624\n",
      "  Epoch 05 | train_loss=0.7536 | val_acc=0.662 | val_F1=0.644\n",
      "Fold 1 final val_acc=0.662, val_macroF1=0.644\n",
      "\n",
      "--- Fold 2/3 ---\n",
      "  Epoch 01 | train_loss=1.0985 | val_acc=0.471 | val_F1=0.466\n",
      "  Epoch 02 | train_loss=1.0257 | val_acc=0.531 | val_F1=0.505\n",
      "  Epoch 03 | train_loss=0.9460 | val_acc=0.592 | val_F1=0.576\n",
      "  Epoch 04 | train_loss=0.8661 | val_acc=0.616 | val_F1=0.602\n",
      "  Epoch 05 | train_loss=0.7661 | val_acc=0.657 | val_F1=0.647\n",
      "Fold 2 final val_acc=0.657, val_macroF1=0.647\n",
      "\n",
      "--- Fold 3/3 ---\n",
      "  Epoch 01 | train_loss=1.0721 | val_acc=0.471 | val_F1=0.464\n",
      "  Epoch 02 | train_loss=0.9911 | val_acc=0.540 | val_F1=0.525\n",
      "  Epoch 03 | train_loss=0.8973 | val_acc=0.584 | val_F1=0.567\n",
      "  Epoch 04 | train_loss=0.7912 | val_acc=0.584 | val_F1=0.562\n",
      "  Epoch 05 | train_loss=0.6974 | val_acc=0.590 | val_F1=0.577\n",
      "Fold 3 final val_acc=0.590, val_macroF1=0.577\n",
      "\n",
      "CV accuracy (mean ± std): 0.636 ± 0.033\n",
      "CV macro-F1 (mean ± std): 0.623 ± 0.033\n",
      "Saved CV artifacts in: /Users/wangzhuoran/Desktop/COGS 109 project/artifacts\n"
     ]
    }
   ],
   "source": [
    "# ---- 5) Model (Variant: ResNet18 fine-tune via timm) ----\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def make_model(num_classes=3, pretrained=True):\n",
    "    \"\"\"\n",
    "    ResNet18 fine-tuning model for minimal car damage classification.\n",
    "    \"\"\"\n",
    "    return timm.create_model(\"resnet18.a1_in1k\", pretrained=pretrained, num_classes=num_classes)\n",
    "\n",
    "# ====== 5.1 Single train/test run (Checkpoint 1 original pipeline) ======\n",
    "\n",
    "# Dataloaders for train/test split\n",
    "train_loader = DataLoader(\n",
    "    FrameDS(train_df, True),\n",
    "    batch_size=32, shuffle=True, num_workers=0, pin_memory=False\n",
    ")\n",
    "test_loader  = DataLoader(\n",
    "    FrameDS(test_df, False),\n",
    "    batch_size=64, shuffle=False, num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = make_model(num_classes=3, pretrained=True).to(DEVICE)\n",
    "\n",
    "# Class weights based on training set (handle imbalance)\n",
    "tc = train_df[\"label\"].value_counts().reindex(CLASSES, fill_value=0).astype(float)\n",
    "N = tc.sum(); K = len(CLASSES)\n",
    "w = torch.tensor([N / (K * tc[c]) for c in CLASSES], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=w)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "EPOCHS = 8  # you can adjust\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item() * x.size(0)\n",
    "    return total / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    yT, yP, yPR = [], [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE)\n",
    "        logits = model(x)\n",
    "        yP.extend(torch.argmax(logits, 1).cpu().numpy())\n",
    "        yPR.extend(torch.softmax(logits, 1).cpu().numpy())\n",
    "        yT.extend(y.numpy())\n",
    "    yT = np.array(yT); yP = np.array(yP); yPR = np.array(yPR)\n",
    "    acc = accuracy_score(yT, yP)\n",
    "    f1m = f1_score(yT, yP, average=\"macro\")\n",
    "    rep = classification_report(yT, yP, target_names=CLASSES, output_dict=True)\n",
    "    return acc, f1m, rep, yT, yP, yPR\n",
    "\n",
    "print(\"===== Train/Test run for Checkpoint-1 model variant =====\")\n",
    "best = 0.0\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    tr_loss = train_one_epoch(model, train_loader, opt, criterion)\n",
    "    acc, f1m, _, _, _, _ = evaluate(model, test_loader)\n",
    "    print(f\"Epoch {ep:02d} | train_loss={tr_loss:.4f} | test_acc={acc:.3f} | macroF1={f1m:.3f}\")\n",
    "    if acc > best:\n",
    "        best = acc\n",
    "        torch.save(model.state_dict(), ART / \"best_checkpoint1.pt\")\n",
    "\n",
    "# Final test evaluation\n",
    "model.load_state_dict(torch.load(ART / \"best_checkpoint1.pt\", map_location=DEVICE))\n",
    "acc, f1m, rep, y_true, y_pred, y_prob = evaluate(model, test_loader)\n",
    "pd.DataFrame(rep).to_csv(ART / \"classification_report_checkpoint1.csv\")\n",
    "print(f\"\\nFINAL — Test Acc: {acc:.3f} | Macro-F1: {f1m:.3f}\")\n",
    "\n",
    "# 1) Baseline vs model accuracy (test set)\n",
    "plt.figure(figsize=(5, 4))\n",
    "vals = [baseline_acc, acc]\n",
    "plt.bar([\"Naive baseline\", \"CNN (ResNet18 FT)\"], vals)\n",
    "plt.ylim(0, 1); plt.ylabel(\"Accuracy\")\n",
    "for i, v in enumerate(vals):\n",
    "    plt.text(i, v + 0.02, f\"{v*100:.1f}%\", ha=\"center\")\n",
    "plt.title(\"Accuracy: Baseline vs CNN (Test Set)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART / \"bar_accuracy_checkpoint1.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# 2) Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])\n",
    "fig, ax = plt.subplots(figsize=(5.2, 4.6))\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "ax.set_xticks([0, 1, 2]); ax.set_xticklabels([c.capitalize() for c in CLASSES], rotation=15)\n",
    "ax.set_yticks([0, 1, 2]); ax.set_yticklabels([c.capitalize() for c in CLASSES])\n",
    "for (i, j), v in np.ndenumerate(cm):\n",
    "    ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\"); ax.set_title(\"Confusion Matrix (Test)\")\n",
    "fig.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART / \"confusion_matrix_checkpoint1.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# 3) ROC (OvR) + macro AUC\n",
    "y_true_ovr = label_binarize(y_true, classes=[0, 1, 2])\n",
    "auc_macro = roc_auc_score(y_true_ovr, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "plt.figure(figsize=(5.6, 4.6))\n",
    "for i, c in enumerate(CLASSES):\n",
    "    fpr, tpr, _ = roc_curve(y_true_ovr[:, i], y_prob[:, i])\n",
    "    plt.plot(fpr, tpr, label=c.capitalize())\n",
    "plt.plot([0, 1], [0, 1], \"--\", linewidth=1)\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
    "plt.title(f\"ROC (OvR) • Macro-AUC={auc_macro:.3f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART / \"roc_ovr_checkpoint1.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "with open(ART / \"metrics_checkpoint1_test.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"baseline_acc\": float(baseline_acc),\n",
    "            \"test_acc\": float(acc),\n",
    "            \"macro_f1\": float(f1m),\n",
    "            \"macro_auc_ovr\": float(auc_macro),\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "print(\"Saved single-run artifacts in:\", ART.resolve())\n",
    "\n",
    "\n",
    "# ====== 5.2 K-fold Cross-Validation for Checkpoint-1 Variant ======\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model_for_cv(m, loader):\n",
    "    \"\"\"\n",
    "    Evaluate model on a CV fold (no need for full report, just acc + macro-F1).\n",
    "    \"\"\"\n",
    "    m.eval()\n",
    "    yT, yP = [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE)\n",
    "        logits = m(x)\n",
    "        yP.extend(torch.argmax(logits, 1).cpu().numpy())\n",
    "        yT.extend(y.numpy())\n",
    "    yT = np.array(yT); yP = np.array(yP)\n",
    "    acc = accuracy_score(yT, yP)\n",
    "    f1m = f1_score(yT, yP, average=\"macro\")\n",
    "    return acc, f1m\n",
    "\n",
    "def train_one_fold(fold_train_df, fold_val_df, num_epochs=5):\n",
    "    \"\"\"\n",
    "    Train a fresh ResNet18 model on one CV fold and return validation metrics.\n",
    "    \"\"\"\n",
    "    fold_train_loader = DataLoader(\n",
    "        FrameDS(fold_train_df, True),\n",
    "        batch_size=32, shuffle=True, num_workers=0, pin_memory=False\n",
    "    )\n",
    "    fold_val_loader = DataLoader(\n",
    "        FrameDS(fold_val_df, False),\n",
    "        batch_size=64, shuffle=False, num_workers=0, pin_memory=False\n",
    "    )\n",
    "\n",
    "    # New model per fold\n",
    "    m = make_model(num_classes=3, pretrained=True).to(DEVICE)\n",
    "\n",
    "    # Class weights based on THIS fold's training data\n",
    "    tc_fold = fold_train_df[\"label\"].value_counts().reindex(CLASSES, fill_value=0).astype(float)\n",
    "    N_fold = tc_fold.sum(); K = len(CLASSES)\n",
    "    w_fold = torch.tensor([N_fold / (K * tc_fold[c]) for c in CLASSES], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    crit_fold = nn.CrossEntropyLoss(weight=w_fold)\n",
    "    opt_fold  = torch.optim.Adam(m.parameters(), lr=1e-4)\n",
    "\n",
    "    for ep in range(1, num_epochs + 1):\n",
    "        m.train()\n",
    "        running = 0.0\n",
    "        for x, y in fold_train_loader:\n",
    "            x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "            opt_fold.zero_grad()\n",
    "            logits = m(x)\n",
    "            loss = crit_fold(logits, y)\n",
    "            loss.backward()\n",
    "            opt_fold.step()\n",
    "            running += loss.item() * x.size(0)\n",
    "        tr_loss = running / len(fold_train_loader.dataset)\n",
    "\n",
    "        val_acc, val_f1 = eval_model_for_cv(m, fold_val_loader)\n",
    "        print(f\"  Epoch {ep:02d} | train_loss={tr_loss:.4f} | val_acc={val_acc:.3f} | val_F1={val_f1:.3f}\")\n",
    "\n",
    "    # Final metrics on validation fold\n",
    "    val_acc, val_f1 = eval_model_for_cv(m, fold_val_loader)\n",
    "    return val_acc, val_f1\n",
    "\n",
    "# ---- Run Stratified K-fold CV on training data ----\n",
    "K_FOLDS = 3   # can change to 5 if you have time\n",
    "labels_int = train_df[\"label\"].map(LBL).values\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "cv_accs, cv_f1s = [], []\n",
    "\n",
    "print(f\"\\n===== {K_FOLDS}-fold Cross-Validation for Checkpoint-1 CNN Variant =====\")\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df[\"path\"], labels_int), 1):\n",
    "    print(f\"\\n--- Fold {fold}/{K_FOLDS} ---\")\n",
    "    fold_train_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    fold_val_df   = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    fold_acc, fold_f1 = train_one_fold(fold_train_df, fold_val_df, num_epochs=5)\n",
    "    print(f\"Fold {fold} final val_acc={fold_acc:.3f}, val_macroF1={fold_f1:.3f}\")\n",
    "\n",
    "    cv_accs.append(fold_acc)\n",
    "    cv_f1s.append(fold_f1)\n",
    "\n",
    "cv_acc_mean  = float(np.mean(cv_accs))\n",
    "cv_acc_std   = float(np.std(cv_accs))\n",
    "cv_f1_mean   = float(np.mean(cv_f1s))\n",
    "cv_f1_std    = float(np.std(cv_f1s))\n",
    "\n",
    "print(f\"\\nCV accuracy (mean ± std): {cv_acc_mean:.3f} ± {cv_acc_std:.3f}\")\n",
    "print(f\"CV macro-F1 (mean ± std): {cv_f1_mean:.3f} ± {cv_f1_std:.3f}\")\n",
    "\n",
    "with open(ART / \"cv_metrics_checkpoint1.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"k_folds\": K_FOLDS,\n",
    "            \"cv_acc_mean\": cv_acc_mean,\n",
    "            \"cv_acc_std\": cv_acc_std,\n",
    "            \"cv_macroF1_mean\": cv_f1_mean,\n",
    "            \"cv_macroF1_std\": cv_f1_std,\n",
    "            \"fold_accs\": [float(x) for x in cv_accs],\n",
    "            \"fold_macroF1s\": [float(x) for x in cv_f1s],\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "# ====== 5.2.1 CV Plots (for slides) ======\n",
    "fold_ids = np.arange(1, K_FOLDS + 1)\n",
    "\n",
    "# (1) CV accuracy by fold + mean + baseline\n",
    "plt.figure(figsize=(5.6, 4.6))\n",
    "plt.bar(fold_ids, cv_accs, width=0.6)\n",
    "plt.axhline(cv_acc_mean, linestyle=\"--\", linewidth=1, label=f\"Mean CV acc = {cv_acc_mean:.3f}\")\n",
    "plt.axhline(baseline_acc, linestyle=\":\", linewidth=1, label=f\"Baseline = {baseline_acc:.3f}\")\n",
    "\n",
    "plt.xticks(fold_ids, [f\"Fold {i}\" for i in fold_ids])\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(f\"{K_FOLDS}-Fold CV Accuracy (Checkpoint-1 CNN)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART / \"cv_accuracy_by_fold_checkpoint1.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# (2) CV macro-F1 by fold + mean\n",
    "plt.figure(figsize=(5.6, 4.6))\n",
    "plt.bar(fold_ids, cv_f1s, width=0.6)\n",
    "plt.axhline(cv_f1_mean, linestyle=\"--\", linewidth=1, label=f\"Mean CV F1 = {cv_f1_mean:.3f}\")\n",
    "\n",
    "plt.xticks(fold_ids, [f\"Fold {i}\" for i in fold_ids])\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Macro-F1\")\n",
    "plt.title(f\"{K_FOLDS}-Fold CV Macro-F1 (Checkpoint-1 CNN)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART / \"cv_macroF1_by_fold_checkpoint1.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved CV artifacts in:\", ART.resolve())\n",
    "# ====== End of Checkpoint-1 model + CV block ======\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b9abb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Variant 1 — ResNet18 FT: AIC / BIC =====\n",
      "Samples (n): 248\n",
      "Parameters (k): 11178051\n",
      "Negative log-likelihood (NLL): 166.03\n",
      "AIC: 22356434.05\n",
      "BIC: 61629719.76\n"
     ]
    }
   ],
   "source": [
    "# ---- AIC/BIC for Variant 1 ----\n",
    "aic_v1, bic_v1 = compute_aic_bic(\n",
    "    model,\n",
    "    test_loader,\n",
    "    variant_name=\"Variant 1 — ResNet18 FT\",\n",
    "    out_json_path=ART / \"aic_bic_variant1.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55defc4f",
   "metadata": {},
   "source": [
    "### 2. Regularized CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Variant 2 — Regularized ResNet18: Test + CV + AIC/BIC =====\n",
      "[V2] Test Accuracy   : 0.694\n",
      "[V2] Test Macro-F1   : 0.689\n",
      "\n",
      "===== V2: K-fold Cross-Validation =====\n",
      "\n",
      "--- Variant 2: Fold 1/3 ---\n",
      "  Epoch 01 | train_loss=1.0987 | val_acc=0.375 | val_F1=0.361\n",
      "  Epoch 02 | train_loss=1.0692 | val_acc=0.445 | val_F1=0.441\n",
      "  Epoch 03 | train_loss=1.0411 | val_acc=0.503 | val_F1=0.499\n",
      "  Epoch 04 | train_loss=1.0143 | val_acc=0.553 | val_F1=0.536\n",
      "  Epoch 05 | train_loss=0.9805 | val_acc=0.575 | val_F1=0.566\n",
      "Fold 1 final val_acc=0.575, val_macroF1=0.566\n",
      "\n",
      "--- Variant 2: Fold 2/3 ---\n",
      "  Epoch 01 | train_loss=1.0962 | val_acc=0.410 | val_F1=0.396\n",
      "  Epoch 02 | train_loss=1.0653 | val_acc=0.482 | val_F1=0.487\n",
      "  Epoch 03 | train_loss=1.0366 | val_acc=0.525 | val_F1=0.529\n",
      "  Epoch 04 | train_loss=1.0099 | val_acc=0.570 | val_F1=0.559\n",
      "  Epoch 05 | train_loss=0.9800 | val_acc=0.584 | val_F1=0.570\n",
      "Fold 2 final val_acc=0.584, val_macroF1=0.570\n",
      "\n",
      "--- Variant 2: Fold 3/3 ---\n",
      "  Epoch 01 | train_loss=1.0883 | val_acc=0.390 | val_F1=0.377\n",
      "  Epoch 02 | train_loss=1.0530 | val_acc=0.460 | val_F1=0.450\n",
      "  Epoch 03 | train_loss=1.0231 | val_acc=0.497 | val_F1=0.487\n",
      "  Epoch 04 | train_loss=0.9875 | val_acc=0.514 | val_F1=0.509\n",
      "  Epoch 05 | train_loss=0.9538 | val_acc=0.534 | val_F1=0.516\n",
      "Fold 3 final val_acc=0.534, val_macroF1=0.516\n",
      "\n",
      "[V2] CV Accuracy (mean ± std): 0.564 ± 0.022\n",
      "[V2] CV Macro-F1 (mean ± std): 0.551 ± 0.024\n",
      "\n",
      "===== Variant 2: AIC / BIC =====\n",
      "Samples (n): 248\n",
      "Parameters (k): 11178051\n",
      "Negative log-likelihood (NLL): 186.75\n",
      "AIC: 22356475.50\n",
      "BIC: 61629761.21\n",
      "\n",
      "===== Variant 2 Summary =====\n",
      "Test Accuracy      : 0.694\n",
      "Test Macro-F1      : 0.689\n",
      "Mean CV Accuracy   : 0.564\n",
      "Mean CV Macro-F1   : 0.551\n",
      "AIC                : 22356475.50\n",
      "BIC                : 61629761.21\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "print(\"\\n===== Variant 2 — Regularized ResNet18: Test + CV + AIC/BIC =====\")\n",
    "\n",
    "# ---------- 1) Dataloaders for Variant 2 (no strong aug) ----------\n",
    "v2_train_loader = DataLoader(\n",
    "    FrameDS(train_df, train=True),   # if your FrameDS ignores `train` or doesn't augment, it's fine\n",
    "    batch_size=32, shuffle=True, num_workers=0, pin_memory=False\n",
    ")\n",
    "v2_test_loader = DataLoader(\n",
    "    FrameDS(test_df, train=False),\n",
    "    batch_size=64, shuffle=False, num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "# ---------- 2) Model + loss (same settings as your V2 training) ----------\n",
    "def make_v2_model(num_classes=3, pretrained=True):\n",
    "    return make_model(num_classes, pretrained)  # same resnet18\n",
    "\n",
    "# reload best weights for test / AIC/BIC\n",
    "model_v2 = make_v2_model(3, True).to(DEVICE)\n",
    "model_v2.load_state_dict(torch.load(ART/\"best_v2.pt\", map_location=DEVICE))\n",
    "\n",
    "# class weights\n",
    "tc_v2 = train_df[\"label\"].value_counts().reindex(CLASSES, fill_value=0).astype(float)\n",
    "N_v2 = tc_v2.sum(); K = len(CLASSES)\n",
    "w_v2 = torch.tensor([N_v2/(K*tc_v2[c]) for c in CLASSES], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "criterion_v2 = nn.CrossEntropyLoss(weight=w_v2, label_smoothing=0.05)\n",
    "opt_v2 = torch.optim.Adam(model_v2.parameters(), lr=5e-5, weight_decay=1e-4)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_v2(loader, m=None):\n",
    "    if m is None:\n",
    "        m = model_v2\n",
    "    m.eval()\n",
    "    yT, yP = [], []\n",
    "    for x,y in loader:\n",
    "        x = x.to(DEVICE)\n",
    "        logits = m(x)\n",
    "        yP.extend(torch.argmax(logits,1).cpu().numpy())\n",
    "        yT.extend(y.numpy())\n",
    "    yT = np.array(yT); yP = np.array(yP)\n",
    "    acc  = accuracy_score(yT,yP)\n",
    "    f1m  = f1_score(yT,yP,average=\"macro\")\n",
    "    return acc, f1m\n",
    "\n",
    "# ---------- 3) Final test metrics for Variant 2 ----------\n",
    "v2_test_acc, v2_test_f1 = eval_v2(v2_test_loader, model_v2)\n",
    "print(f\"[V2] Test Accuracy   : {v2_test_acc:.3f}\")\n",
    "print(f\"[V2] Test Macro-F1   : {v2_test_f1:.3f}\")\n",
    "\n",
    "# ---------- 4) K-fold Cross-Validation (same style as Variant 3) ----------\n",
    "print(\"\\n===== V2: K-fold Cross-Validation =====\")\n",
    "\n",
    "def train_one_fold_v2(fold_train_df, fold_val_df, num_epochs=5):\n",
    "    fold_train_loader = DataLoader(\n",
    "        FrameDS(fold_train_df, train=True),\n",
    "        batch_size=32, shuffle=True, num_workers=0, pin_memory=False\n",
    "    )\n",
    "    fold_val_loader = DataLoader(\n",
    "        FrameDS(fold_val_df, train=False),\n",
    "        batch_size=64, shuffle=False, num_workers=0, pin_memory=False\n",
    "    )\n",
    "\n",
    "    m = make_v2_model(3, True).to(DEVICE)\n",
    "\n",
    "    # class weights per fold\n",
    "    tc_fold = fold_train_df[\"label\"].value_counts().reindex(CLASSES, fill_value=0).astype(float)\n",
    "    N_fold = tc_fold.sum(); K = len(CLASSES)\n",
    "    w_fold = torch.tensor([N_fold/(K*tc_fold[c]) for c in CLASSES], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    crit_fold = nn.CrossEntropyLoss(weight=w_fold, label_smoothing=0.05)\n",
    "    opt_fold  = torch.optim.Adam(m.parameters(), lr=5e-5, weight_decay=1e-4)\n",
    "\n",
    "    for ep in range(1, num_epochs+1):\n",
    "        m.train(); total = 0.0\n",
    "        for x,y in fold_train_loader:\n",
    "            x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "            opt_fold.zero_grad()\n",
    "            logits = m(x)\n",
    "            loss = crit_fold(logits,y)\n",
    "            loss.backward(); opt_fold.step()\n",
    "            total += loss.item()*x.size(0)\n",
    "        tr_loss = total/len(fold_train_loader.dataset)\n",
    "        val_acc, val_f1 = eval_v2(fold_val_loader, m)\n",
    "        print(f\"  Epoch {ep:02d} | train_loss={tr_loss:.4f} | val_acc={val_acc:.3f} | val_F1={val_f1:.3f}\")\n",
    "\n",
    "    val_acc, val_f1 = eval_v2(fold_val_loader, m)\n",
    "    return val_acc, val_f1\n",
    "\n",
    "K_FOLDS_V2 = 3\n",
    "labels_int_v2 = train_df[\"label\"].map(LBL).values\n",
    "skf_v2 = StratifiedKFold(n_splits=K_FOLDS_V2, shuffle=True, random_state=SEED)\n",
    "\n",
    "cv_accs_v2, cv_f1s_v2 = [], []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf_v2.split(train_df[\"path\"], labels_int_v2), 1):\n",
    "    print(f\"\\n--- Variant 2: Fold {fold}/{K_FOLDS_V2} ---\")\n",
    "    fold_train_df = train_df.iloc[tr_idx].reset_index(drop=True)\n",
    "    fold_val_df   = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    fold_acc, fold_f1 = train_one_fold_v2(fold_train_df, fold_val_df, num_epochs=5)\n",
    "    print(f\"Fold {fold} final val_acc={fold_acc:.3f}, val_macroF1={fold_f1:.3f}\")\n",
    "    cv_accs_v2.append(fold_acc); cv_f1s_v2.append(fold_f1)\n",
    "\n",
    "cv_acc_mean_v2 = float(np.mean(cv_accs_v2))\n",
    "cv_acc_std_v2  = float(np.std(cv_accs_v2))\n",
    "cv_f1_mean_v2  = float(np.mean(cv_f1s_v2))\n",
    "cv_f1_std_v2   = float(np.std(cv_f1s_v2))\n",
    "\n",
    "print(f\"\\n[V2] CV Accuracy (mean ± std): {cv_acc_mean_v2:.3f} ± {cv_acc_std_v2:.3f}\")\n",
    "print(f\"[V2] CV Macro-F1 (mean ± std): {cv_f1_mean_v2:.3f} ± {cv_f1_std_v2:.3f}\")\n",
    "\n",
    "with open(ART/\"cv_metrics_v2.json\",\"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"k_folds\": K_FOLDS_V2,\n",
    "            \"cv_acc_mean\": cv_acc_mean_v2,\n",
    "            \"cv_acc_std\": cv_acc_std_v2,\n",
    "            \"cv_macroF1_mean\": cv_f1_mean_v2,\n",
    "            \"cv_macroF1_std\": cv_f1_std_v2,\n",
    "            \"fold_accs\": [float(x) for x in cv_accs_v2],\n",
    "            \"fold_macroF1s\": [float(x) for x in cv_f1s_v2],\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "# ---------- 5) AIC / BIC on test set ----------\n",
    "aic_v2, bic_v2 = compute_aic_bic(\n",
    "    model_v2,\n",
    "    v2_test_loader,\n",
    "    variant_name=\"Variant 2\",\n",
    "    out_json_path=ART/\"aic_bic_v2.json\"\n",
    ")\n",
    "\n",
    "# ---------- 6) Final one-line summary for slide ----------\n",
    "print(\"\\n===== Variant 2 Summary =====\")\n",
    "print(f\"Test Accuracy      : {v2_test_acc:.3f}\")\n",
    "print(f\"Test Macro-F1      : {v2_test_f1:.3f}\")\n",
    "print(f\"Mean CV Accuracy   : {cv_acc_mean_v2:.3f}\")\n",
    "print(f\"Mean CV Macro-F1   : {cv_f1_mean_v2:.3f}\")\n",
    "print(f\"AIC                : {aic_v2:.2f}\")\n",
    "print(f\"BIC                : {bic_v2:.2f}\")\n",
    "print(\"=====================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78c3a9",
   "metadata": {},
   "source": [
    "### 3. Augmented ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a5ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Variant 3 — Augmented ResNet18: Train/Test run =====\n",
      "No existing weights found, start training Augmented Variant...\n",
      "Epoch 01 | train_loss=1.0797 | test_acc=0.516 | macroF1=0.511\n",
      "  -> New best test acc, model saved to artifacts/best_aug_variant.pt\n",
      "Epoch 02 | train_loss=1.0064 | test_acc=0.645 | macroF1=0.627\n",
      "  -> New best test acc, model saved to artifacts/best_aug_variant.pt\n",
      "Epoch 03 | train_loss=0.9133 | test_acc=0.685 | macroF1=0.654\n",
      "  -> New best test acc, model saved to artifacts/best_aug_variant.pt\n",
      "Epoch 04 | train_loss=0.8139 | test_acc=0.706 | macroF1=0.690\n",
      "  -> New best test acc, model saved to artifacts/best_aug_variant.pt\n",
      "Epoch 05 | train_loss=0.7510 | test_acc=0.702 | macroF1=0.684\n",
      "Epoch 06 | train_loss=0.6961 | test_acc=0.714 | macroF1=0.707\n",
      "  -> New best test acc, model saved to artifacts/best_aug_variant.pt\n",
      "Epoch 07 | train_loss=0.6541 | test_acc=0.710 | macroF1=0.702\n",
      "Epoch 08 | train_loss=0.6197 | test_acc=0.726 | macroF1=0.712\n",
      "  -> New best test acc, model saved to artifacts/best_aug_variant.pt\n",
      "\n",
      "[Augmented Variant] FINAL — Test Acc: 0.726 | Macro-F1: 0.712\n",
      "Saved Augmented Variant test artifacts in: /Users/wangzhuoran/Desktop/COGS 109 project/artifacts\n",
      "\n",
      "===== K-fold Cross-Validation for Augmented Variant =====\n",
      "\n",
      "--- Augmented Variant: Fold 1/3 ---\n",
      "  Epoch 01 | train_loss=1.0838 | val_acc=0.492 | val_F1=0.447\n",
      "  Epoch 02 | train_loss=1.0353 | val_acc=0.570 | val_F1=0.526\n",
      "  Epoch 03 | train_loss=0.9782 | val_acc=0.618 | val_F1=0.582\n",
      "  Epoch 04 | train_loss=0.9070 | val_acc=0.646 | val_F1=0.605\n",
      "  Epoch 05 | train_loss=0.8525 | val_acc=0.683 | val_F1=0.656\n",
      "Fold 1 final val_acc=0.683, val_macroF1=0.656\n",
      "\n",
      "--- Augmented Variant: Fold 2/3 ---\n",
      "  Epoch 01 | train_loss=1.0806 | val_acc=0.434 | val_F1=0.427\n",
      "  Epoch 02 | train_loss=1.0277 | val_acc=0.527 | val_F1=0.527\n",
      "  Epoch 03 | train_loss=0.9616 | val_acc=0.599 | val_F1=0.589\n",
      "  Epoch 04 | train_loss=0.9018 | val_acc=0.629 | val_F1=0.606\n",
      "  Epoch 05 | train_loss=0.8291 | val_acc=0.640 | val_F1=0.628\n",
      "Fold 2 final val_acc=0.640, val_macroF1=0.628\n",
      "\n",
      "--- Augmented Variant: Fold 3/3 ---\n",
      "  Epoch 01 | train_loss=1.0807 | val_acc=0.460 | val_F1=0.449\n",
      "  Epoch 02 | train_loss=1.0219 | val_acc=0.523 | val_F1=0.511\n",
      "  Epoch 03 | train_loss=0.9572 | val_acc=0.547 | val_F1=0.545\n",
      "  Epoch 04 | train_loss=0.8690 | val_acc=0.562 | val_F1=0.554\n",
      "  Epoch 05 | train_loss=0.7850 | val_acc=0.581 | val_F1=0.583\n",
      "Fold 3 final val_acc=0.581, val_macroF1=0.583\n",
      "\n",
      "[Augmented Variant] CV accuracy (mean ± std): 0.635 ± 0.042\n",
      "[Augmented Variant] CV macro-F1 (mean ± std): 0.622 ± 0.030\n",
      "Saved Augmented Variant CV artifacts in: /Users/wangzhuoran/Desktop/COGS 109 project/artifacts\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Variant 3 — Augmented ResNet18 (stronger data augmentation)\n",
    "# ============================================================\n",
    "import random\n",
    "from PIL import ImageEnhance\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# ---------- 1) Augmentation utilities ----------\n",
    "\n",
    "def augment_to_tensor(img: Image.Image):\n",
    "    \"\"\"\n",
    "    Stronger augmentation for training:\n",
    "      - Convert to RGB\n",
    "      - Random rotation in [-20°, +20°]\n",
    "      - Random crop to 224x224 (with resize if needed)\n",
    "      - Mild color jitter (brightness, contrast, saturation ∈ [0.8, 1.2])\n",
    "      - Normalize with ImageNet mean/std and convert to CHW tensor\n",
    "    \"\"\"\n",
    "    img = img.convert(\"RGB\")\n",
    "\n",
    "    # Random rotation\n",
    "    angle = random.uniform(-20.0, 20.0)\n",
    "    img = img.rotate(angle, resample=Image.BILINEAR, expand=False)\n",
    "\n",
    "    # Random resize / crop to IMSIZE x IMSIZE (e.g., 224)\n",
    "    w, h = img.size\n",
    "    if w < IMSIZE or h < IMSIZE:\n",
    "        # scale up so both sides >= IMSIZE\n",
    "        scale = max(IMSIZE / w, IMSIZE / h)\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "        img = img.resize((new_w, new_h), Image.BILINEAR)\n",
    "        w, h = img.size\n",
    "\n",
    "    # If still larger than IMSIZE, random crop\n",
    "    if w > IMSIZE and h > IMSIZE:\n",
    "        left = random.randint(0, w - IMSIZE)\n",
    "        top = random.randint(0, h - IMSIZE)\n",
    "        img = img.crop((left, top, left + IMSIZE, top + IMSIZE))\n",
    "    else:\n",
    "        # fallback to center-ish resize\n",
    "        img = img.resize((IMSIZE, IMSIZE), Image.BILINEAR)\n",
    "\n",
    "    # Mild color jitter: brightness, contrast, saturation\n",
    "    for Enhancer in (ImageEnhance.Brightness, ImageEnhance.Contrast, ImageEnhance.Color):\n",
    "        factor = random.uniform(0.8, 1.2)\n",
    "        img = Enhancer(img).enhance(factor)\n",
    "\n",
    "    # To tensor + normalize (same as your original to_tensor)\n",
    "    arr = np.asarray(img).astype(\"float32\") / 255.0\n",
    "    arr = (arr - IMNET_MEAN) / IMNET_STD\n",
    "    arr = arr.transpose(2, 0, 1)  # CHW\n",
    "    return torch.from_numpy(arr)\n",
    "\n",
    "\n",
    "class AugFrameDS(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for Augmented Variant:\n",
    "      - train=True  -> strong augmentation (augment_to_tensor)\n",
    "      - train=False -> plain normalization (to_tensor)\n",
    "    \"\"\"\n",
    "    def __init__(self, frame: pd.DataFrame, train: bool = False):\n",
    "        self.df = frame.reset_index(drop=True).copy()\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row[\"path\"])\n",
    "        if self.train:\n",
    "            x = augment_to_tensor(img)\n",
    "        else:\n",
    "            x = to_tensor(img)   # use your original normalization\n",
    "        y = LBL[row[\"label\"]]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# ---------- 2) Model factory (same as Variant 1) ----------\n",
    "\n",
    "def make_aug_model(num_classes=3, pretrained=True):\n",
    "    \"\"\"\n",
    "    Same architecture as Variant 1 (ResNet18),\n",
    "    but we will treat this as Variant 3 with data augmentation.\n",
    "    \"\"\"\n",
    "    return timm.create_model(\"resnet18.a1_in1k\", pretrained=pretrained, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2.1 Single Train/Test run for Augmented Variant (no CV)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n===== Variant 3 — Augmented ResNet18: Train/Test run =====\")\n",
    "\n",
    "# Dataloaders for this variant\n",
    "aug_train_loader = DataLoader(\n",
    "    AugFrameDS(train_df, train=True),\n",
    "    batch_size=32, shuffle=True, num_workers=0, pin_memory=False\n",
    ")\n",
    "aug_test_loader = DataLoader(\n",
    "    AugFrameDS(test_df, train=False),\n",
    "    batch_size=64, shuffle=False, num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "AUG_WEIGHTS = ART / \"best_aug_variant.pt\"\n",
    "EPOCHS_AUG = 8\n",
    "\n",
    "# Class weights based on training data\n",
    "tc_aug = train_df[\"label\"].value_counts().reindex(CLASSES, fill_value=0).astype(float)\n",
    "N_aug = tc_aug.sum()\n",
    "K = len(CLASSES)\n",
    "w_aug = torch.tensor([N_aug / (K * tc_aug[c]) for c in CLASSES], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "# Define model, loss, optimizer\n",
    "aug_model = make_aug_model(num_classes=3, pretrained=True).to(DEVICE)\n",
    "aug_criterion = nn.CrossEntropyLoss(weight=w_aug)\n",
    "aug_opt = torch.optim.Adam(aug_model.parameters(), lr=1e-4)\n",
    "\n",
    "def train_one_epoch_aug():\n",
    "    aug_model.train()\n",
    "    total = 0.0\n",
    "    for x, y in aug_train_loader:\n",
    "        x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "        aug_opt.zero_grad()\n",
    "        logits = aug_model(x)\n",
    "        loss = aug_criterion(logits, y)\n",
    "        loss.backward()\n",
    "        aug_opt.step()\n",
    "        total += loss.item() * x.size(0)\n",
    "    return total / len(aug_train_loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_aug(loader):\n",
    "    aug_model.eval()\n",
    "    yT, yP, yPR = [], [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE)\n",
    "        logits = aug_model(x)\n",
    "        yP.extend(torch.argmax(logits, 1).cpu().numpy())\n",
    "        yPR.extend(torch.softmax(logits, 1).cpu().numpy())\n",
    "        yT.extend(y.numpy())\n",
    "    yT = np.array(yT); yP = np.array(yP); yPR = np.array(yPR)\n",
    "    acc = accuracy_score(yT, yP)\n",
    "    f1m = f1_score(yT, yP, average=\"macro\")\n",
    "    rep = classification_report(yT, yP, target_names=CLASSES, output_dict=True)\n",
    "    return acc, f1m, rep, yT, yP, yPR\n",
    "\n",
    "if AUG_WEIGHTS.exists():\n",
    "    print(f\"Found existing weights at {AUG_WEIGHTS}, skipping training.\")\n",
    "    aug_model.load_state_dict(torch.load(AUG_WEIGHTS, map_location=DEVICE))\n",
    "else:\n",
    "    print(\"No existing weights found, start training Augmented Variant...\")\n",
    "    best_aug = 0.0\n",
    "    for ep in range(1, EPOCHS_AUG + 1):\n",
    "        tr_loss = train_one_epoch_aug()\n",
    "        acc_ep, f1_ep, _, _, _, _ = evaluate_aug(aug_test_loader)\n",
    "        print(f\"Epoch {ep:02d} | train_loss={tr_loss:.4f} | test_acc={acc_ep:.3f} | macroF1={f1_ep:.3f}\")\n",
    "        if acc_ep > best_aug:\n",
    "            best_aug = acc_ep\n",
    "            torch.save(aug_model.state_dict(), AUG_WEIGHTS)\n",
    "            print(f\"  -> New best test acc, model saved to {AUG_WEIGHTS}\")\n",
    "\n",
    "    aug_model.load_state_dict(torch.load(AUG_WEIGHTS, map_location=DEVICE))\n",
    "\n",
    "# Final test evaluation\n",
    "aug_acc, aug_f1, aug_rep, aug_y_true, aug_y_pred, aug_y_prob = evaluate_aug(aug_test_loader)\n",
    "pd.DataFrame(aug_rep).to_csv(ART / \"classification_report_aug_variant_test.csv\")\n",
    "print(f\"\\n[Augmented Variant] FINAL — Test Acc: {aug_acc:.3f} | Macro-F1: {aug_f1:.3f}\")\n",
    "\n",
    "# ---------- 2.1.1 Figures for Augmented Variant (new figures) ----------\n",
    "\n",
    "# (1) Baseline vs Augmented model accuracy on test set\n",
    "plt.figure(figsize=(5, 4))\n",
    "vals = [baseline_acc, aug_acc]\n",
    "plt.bar([\"Naive baseline\", \"Augmented CNN\"], vals)\n",
    "plt.ylim(0, 1); plt.ylabel(\"Accuracy\")\n",
    "for i, v in enumerate(vals):\n",
    "    plt.text(i, v + 0.02, f\"{v*100:.1f}%\", ha=\"center\")\n",
    "plt.title(\"Accuracy: Baseline vs Augmented CNN (Test Set)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART / \"bar_accuracy_aug_variant.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# (2) Confusion matrix (Augmented variant)\n",
    "cm_aug = confusion_matrix(aug_y_true, aug_y_pred, labels=[0, 1, 2])\n",
    "fig, ax = plt.subplots(figsize=(5.2, 4.6))\n",
    "im = ax.imshow(cm_aug, cmap=\"Blues\")\n",
    "ax.set_xticks([0, 1, 2]); ax.set_xticklabels([c.capitalize() for c in CLASSES], rotation=15)\n",
    "ax.set_yticks([0, 1, 2]); ax.set_yticklabels([c.capitalize() for c in CLASSES])\n",
    "for (i, j), v in np.ndenumerate(cm_aug):\n",
    "    ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\"); ax.set_title(\"Confusion Matrix (Augmented CNN)\")\n",
    "fig.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART / \"confusion_matrix_aug_variant.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# (3) ROC (OvR) + macro AUC for Augmented variant\n",
    "aug_y_true_ovr = label_binarize(aug_y_true, classes=[0, 1, 2])\n",
    "aug_auc_macro = roc_auc_score(aug_y_true_ovr, aug_y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "plt.figure(figsize=(5.6, 4.6))\n",
    "for i, c in enumerate(CLASSES):\n",
    "    fpr, tpr, _ = roc_curve(aug_y_true_ovr[:, i], aug_y_prob[:, i])\n",
    "    plt.plot(fpr, tpr, label=c.capitalize())\n",
    "plt.plot([0, 1], [0, 1], \"--\", linewidth=1)\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
    "plt.title(f\"Augmented CNN ROC (OvR) • Macro-AUC={aug_auc_macro:.3f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART / \"roc_ovr_aug_variant.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "with open(ART / \"metrics_aug_variant_test.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"baseline_acc\": float(baseline_acc),\n",
    "            \"test_acc\": float(aug_acc),\n",
    "            \"macro_f1\": float(aug_f1),\n",
    "            \"macro_auc_ovr\": float(aug_auc_macro),\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "print(\"Saved Augmented Variant test artifacts in:\", ART.resolve())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2.2 K-fold Cross-Validation for Augmented Variant\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n===== K-fold Cross-Validation for Augmented Variant =====\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model_for_cv_aug(m, loader):\n",
    "    m.eval()\n",
    "    yT, yP = [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE)\n",
    "        logits = m(x)\n",
    "        yP.extend(torch.argmax(logits, 1).cpu().numpy())\n",
    "        yT.extend(y.numpy())\n",
    "    yT = np.array(yT); yP = np.array(yP)\n",
    "    acc = accuracy_score(yT, yP)\n",
    "    f1m = f1_score(yT, yP, average=\"macro\")\n",
    "    return acc, f1m\n",
    "\n",
    "def train_one_fold_aug(fold_train_df, fold_val_df, num_epochs=5):\n",
    "    \"\"\"\n",
    "    Train Augmented ResNet18 on one CV fold:\n",
    "      - train fold: with augmentation\n",
    "      - val fold: only normalization\n",
    "    \"\"\"\n",
    "    fold_train_loader = DataLoader(\n",
    "        AugFrameDS(fold_train_df, train=True),\n",
    "        batch_size=32, shuffle=True, num_workers=0, pin_memory=False\n",
    "    )\n",
    "    fold_val_loader = DataLoader(\n",
    "        AugFrameDS(fold_val_df, train=False),\n",
    "        batch_size=64, shuffle=False, num_workers=0, pin_memory=False\n",
    "    )\n",
    "\n",
    "    m = make_aug_model(num_classes=3, pretrained=True).to(DEVICE)\n",
    "\n",
    "    # Class weights from this fold's train data\n",
    "    tc_fold = fold_train_df[\"label\"].value_counts().reindex(CLASSES, fill_value=0).astype(float)\n",
    "    N_fold = tc_fold.sum()\n",
    "    K = len(CLASSES)\n",
    "    w_fold = torch.tensor([N_fold / (K * tc_fold[c]) for c in CLASSES], dtype=torch.float32, device=DEVICE)\n",
    "    crit_fold = nn.CrossEntropyLoss(weight=w_fold)\n",
    "    opt_fold = torch.optim.Adam(m.parameters(), lr=1e-4)\n",
    "\n",
    "    for ep in range(1, num_epochs + 1):\n",
    "        m.train()\n",
    "        total = 0.0\n",
    "        for x, y in fold_train_loader:\n",
    "            x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "            opt_fold.zero_grad()\n",
    "            logits = m(x)\n",
    "            loss = crit_fold(logits, y)\n",
    "            loss.backward()\n",
    "            opt_fold.step()\n",
    "            total += loss.item() * x.size(0)\n",
    "        tr_loss = total / len(fold_train_loader.dataset)\n",
    "\n",
    "        val_acc, val_f1 = eval_model_for_cv_aug(m, fold_val_loader)\n",
    "        print(f\"  Epoch {ep:02d} | train_loss={tr_loss:.4f} | val_acc={val_acc:.3f} | val_F1={val_f1:.3f}\")\n",
    "\n",
    "    # final val metrics\n",
    "    val_acc, val_f1 = eval_model_for_cv_aug(m, fold_val_loader)\n",
    "    return val_acc, val_f1\n",
    "\n",
    "K_FOLDS_AUG = 3  # same k as Variant 1 for fair comparison\n",
    "labels_int_aug = train_df[\"label\"].map(LBL).values\n",
    "skf_aug = StratifiedKFold(n_splits=K_FOLDS_AUG, shuffle=True, random_state=SEED)\n",
    "\n",
    "cv_accs_aug, cv_f1s_aug = [], []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf_aug.split(train_df[\"path\"], labels_int_aug), 1):\n",
    "    print(f\"\\n--- Augmented Variant: Fold {fold}/{K_FOLDS_AUG} ---\")\n",
    "    fold_train_df = train_df.iloc[tr_idx].reset_index(drop=True)\n",
    "    fold_val_df   = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    fold_acc, fold_f1 = train_one_fold_aug(fold_train_df, fold_val_df, num_epochs=5)\n",
    "    print(f\"Fold {fold} final val_acc={fold_acc:.3f}, val_macroF1={fold_f1:.3f}\")\n",
    "\n",
    "    cv_accs_aug.append(fold_acc)\n",
    "    cv_f1s_aug.append(fold_f1)\n",
    "\n",
    "cv_acc_mean_aug = float(np.mean(cv_accs_aug))\n",
    "cv_acc_std_aug  = float(np.std(cv_accs_aug))\n",
    "cv_f1_mean_aug  = float(np.mean(cv_f1s_aug))\n",
    "cv_f1_std_aug   = float(np.std(cv_f1s_aug))\n",
    "\n",
    "print(f\"\\n[Augmented Variant] CV accuracy (mean ± std): {cv_acc_mean_aug:.3f} ± {cv_acc_std_aug:.3f}\")\n",
    "print(f\"[Augmented Variant] CV macro-F1 (mean ± std): {cv_f1_mean_aug:.3f} ± {cv_f1_std_aug:.3f}\")\n",
    "\n",
    "with open(ART / \"cv_metrics_aug_variant.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"k_folds\": K_FOLDS_AUG,\n",
    "            \"cv_acc_mean\": cv_acc_mean_aug,\n",
    "            \"cv_acc_std\": cv_acc_std_aug,\n",
    "            \"cv_macroF1_mean\": cv_f1_mean_aug,\n",
    "            \"cv_macroF1_std\": cv_f1_std_aug,\n",
    "            \"fold_accs\": [float(x) for x in cv_accs_aug],\n",
    "            \"fold_macroF1s\": [float(x) for x in cv_f1s_aug],\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "# ---------- 2.2.1 CV plots for Augmented Variant ----------\n",
    "\n",
    "fold_ids_aug = np.arange(1, K_FOLDS_AUG + 1)\n",
    "\n",
    "# (1) CV accuracy by fold + mean + baseline\n",
    "plt.figure(figsize=(5.6, 4.6))\n",
    "plt.bar(fold_ids_aug, cv_accs_aug, width=0.6)\n",
    "plt.axhline(cv_acc_mean_aug, linestyle=\"--\", linewidth=1, label=f\"Mean CV acc = {cv_acc_mean_aug:.3f}\")\n",
    "plt.axhline(baseline_acc, linestyle=\":\", linewidth=1, label=f\"Baseline = {baseline_acc:.3f}\")\n",
    "plt.xticks(fold_ids_aug, [f\"Fold {i}\" for i in fold_ids_aug])\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(f\"{K_FOLDS_AUG}-Fold CV Accuracy (Augmented CNN)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART / \"cv_accuracy_by_fold_aug_variant.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# (2) CV macro-F1 by fold + mean\n",
    "plt.figure(figsize=(5.6, 4.6))\n",
    "plt.bar(fold_ids_aug, cv_f1s_aug, width=0.6)\n",
    "plt.axhline(cv_f1_mean_aug, linestyle=\"--\", linewidth=1, label=f\"Mean CV F1 = {cv_f1_mean_aug:.3f}\")\n",
    "plt.xticks(fold_ids_aug, [f\"Fold {i}\" for i in fold_ids_aug])\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Macro-F1\")\n",
    "plt.title(f\"{K_FOLDS_AUG}-Fold CV Macro-F1 (Augmented CNN)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART / \"cv_macroF1_by_fold_aug_variant.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved Augmented Variant CV artifacts in:\", ART.resolve())\n",
    "# =================== End of Variant 3 ===================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6449aac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Variant 3 — Augmented ResNet18: AIC / BIC =====\n",
      "Samples (n): 248\n",
      "Parameters (k): 11178051\n",
      "Negative log-likelihood (NLL): 157.17\n",
      "AIC: 22356416.35\n",
      "BIC: 61629702.06\n"
     ]
    }
   ],
   "source": [
    "# ---- AIC/BIC for Variant 3 (Augmented) ----\n",
    "aic_v3, bic_v3 = compute_aic_bic(\n",
    "    aug_model,\n",
    "    aug_test_loader,\n",
    "    variant_name=\"Variant 3 — Augmented ResNet18\",\n",
    "    out_json_path=ART / \"aic_bic_variant3_augmented.json\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
